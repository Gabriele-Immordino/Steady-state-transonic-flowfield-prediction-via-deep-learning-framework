{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Dropout, Input, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, TimeDistributed\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU memory configuration\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262a854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load experimental data\n",
    "exp_0_deg = [\n",
    "    0.849617672047573, 0,\n",
    "    10.4078164825828, -0.0357142857142858,\n",
    "    25.2761257434155, -0.0779220779220779,\n",
    "    50.339847068819, -0.194805194805195,\n",
    "    100.254885301614, -0.470779220779221,\n",
    "    152.293967714528, -0.876623376623377\n",
    "]\n",
    "\n",
    "exp_0_deg_q = exp_0_deg[0::2]\n",
    "exp_0_deg_theta = exp_0_deg[1::2]\n",
    "\n",
    "exp_1_15_deg = [\n",
    "    50.339847068819, -0.0714285714285714,\n",
    "    169.498725573492, -0.321428571428571,\n",
    "    204.333050127443, -0.457792207792208\n",
    "]\n",
    "\n",
    "exp_1_15_deg_q = exp_1_15_deg[0::2]\n",
    "exp_1_15_deg_theta = exp_1_15_deg[1::2]\n",
    "\n",
    "exp_3_15_deg = [\n",
    "    0.849617672047573, 0.00649350649350655,\n",
    "    10.4078164825828, 0.0324675324675323,\n",
    "    50.339847068819, 0.220779220779221,\n",
    "    100.254885301614, 0.487012987012987,\n",
    "     115.335598980459, 0.594155844155844,\n",
    "    135.301614273577, 0.75,\n",
    "    152.293967714528, 0.902597402597403,\n",
    "    169.28632115548, 1.07467532467532\n",
    "]\n",
    "\n",
    "exp_3_15_deg_q = exp_3_15_deg[0::2]\n",
    "exp_3_15_deg_theta = exp_3_15_deg[1::2]\n",
    "\n",
    "exp_4_deg = [\n",
    "    50.1274426508071, 0.327922077922078,\n",
    "    134.876805437553, 1.22727272727273,\n",
    "    169.073916737468, 1.62012987012987,\n",
    "    203.908241291419, 2.2012987012987\n",
    "]\n",
    "\n",
    "exp_4_deg_q = exp_4_deg[0::2]\n",
    "exp_4_deg_theta = exp_4_deg[1::2]\n",
    "\n",
    "exp_5_deg = [\n",
    "    0.637213254035684, 0.00649350649350655,\n",
    "    24.6389124893798, 0.214285714285714,\n",
    "    49.9150382327952, 0.464285714285714,\n",
    "    74.553950722175, 0.733766233766234,\n",
    "    100.042480883602, 1.04545454545455,\n",
    "    120.00849617672, 1.33116883116883,\n",
    "    135.514018691589,1.54911499194776,\n",
    "    152.081563296517,1.8022657092623,\n",
    "    169.28632115548,2.0651529926274\n",
    "]\n",
    "\n",
    "exp_5_deg_q = exp_5_deg[0::2]\n",
    "exp_5_deg_theta = exp_5_deg[1::2]\n",
    "\n",
    "exp_6_5_deg = [\n",
    "    0.637213254035684, 0,\n",
    "    10.4078164825828, 0.0844155844155845,\n",
    "    25.0637213254036, 0.217532467532468,\n",
    "    50.1274426508071, 0.37987012987013,\n",
    "    100.254885301614, 0.727272727272727,\n",
    "    135.089209855565, 0.996753246753247,\n",
    "    152.293967714528, 1.12662337662338,\n",
    "    169.073916737468, 1.2987012987013\n",
    "]\n",
    "\n",
    "exp_6_5_deg_q = exp_6_5_deg[0::2]\n",
    "exp_6_5_deg_theta = exp_6_5_deg[1::2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4070e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'Model_architecture\\\\FCNN_v1\\\\'\n",
    "\n",
    "# Inputs for aerodynamic forces estimation\n",
    "xref = 0.12192          # Reference point for moment calculation (m)\n",
    "chord = 0.4064          # Chord length of the wing (m)\n",
    "x_30 = 0.12192          # 30% chord location (m)\n",
    "x_50 = 0.2032           # 50% chord location (m)\n",
    "span = chord*2          # Span of the wing (m)\n",
    "area = span*chord       # Reference area (m^2)\n",
    "\n",
    "\n",
    "# Create directories for the results\n",
    "directory_results = 'Results\\\\Static_deformation\\\\'\n",
    "Path(directory_results).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "dataset = np.load('Dataset_NN\\\\dataset.npy')\n",
    "grid_data = 'Dataset\\\\grid_data.dat'\n",
    "CFD_csv_file = 'Dataset\\\\surface.csv' # File with normals and cell area\n",
    "\n",
    "# print( '\\n-> Shape of the loaded matrix: \\n')\n",
    "# print(dataset.shape) # x, y , z , CP , CF_x, CF_y, CF_z, M , AoA\n",
    "\n",
    "X = dataset[:,:,[0,1,2,7,8]] # Input\n",
    "Y = dataset[:,:,3:7]         # Output\n",
    "\n",
    "\n",
    "## Feature normalisation:\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "samples, points, variables = X.shape\n",
    "X = np.reshape(X, newshape=(-1, variables))\n",
    "X = scaler.fit_transform(X)\n",
    "X = np.reshape(X, newshape=(samples, points, variables))\n",
    "#print(X.shape)\n",
    "scalery = MinMaxScaler(feature_range=(-1, 1))\n",
    "# Y = np.expand_dims(Y,axis=2)\n",
    "samples, points, variables = Y.shape\n",
    "Y = np.reshape(Y, newshape=(-1, variables))\n",
    "Y = scalery.fit_transform(Y)\n",
    "Y = np.reshape(Y, newshape=(samples, points, variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaa197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_dir+ 'neural_network_model.h5')\n",
    "model.load_weights(model_dir+ 'neural_network_weights.h5')\n",
    "print(model.summary())\n",
    "\n",
    "# Denormalize\n",
    "samples, points, variables = X.shape\n",
    "X_test = np.reshape(X, newshape=(-1, variables))\n",
    "X_test = scaler.inverse_transform(X_test)\n",
    "X_test = np.reshape(X_test, newshape=(samples, points, variables))\n",
    "\n",
    "cooordinates = pd.read_csv(CFD_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce10058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(Mach, AoA, npts, X_temp):\n",
    "  \"\"\"\n",
    "  Predicts aerodynamic lift and moment using a trained neural network model.\n",
    "\n",
    "  Parameters:\n",
    "    Mach (float): Mach number for prediction.\n",
    "    AoA (float): Angle of attack in degrees.\n",
    "    npts (int): Number of points in the input grid.\n",
    "    X_temp (np.ndarray): Input grid coordinates (npts x 3).\n",
    "\n",
    "  Returns:\n",
    "    tuple: (lift_NN, moment_NN) - Predicted lift and moment.\n",
    "  \"\"\"\n",
    "  # Create arrays for Mach and AoA for each point\n",
    "  Mach_i = np.full((npts, 1), Mach)  # Mach column\n",
    "  AoA_i = np.full((npts, 1), AoA)    # AoA column\n",
    "\n",
    "  # Concatenate coordinates with Mach and AoA\n",
    "  X_exp = np.concatenate((X_temp, Mach_i, AoA_i), axis=1)  # Shape: (npts, 5)\n",
    "\n",
    "  # Normalize input features\n",
    "  X_exp = scaler.transform(X_exp)\n",
    "  X_exp = np.expand_dims(X_exp, axis=0)  # Add batch dimension\n",
    "\n",
    "  # Predict using the neural network model\n",
    "  Y_exp_pred = model.predict(X_exp, batch_size=1, verbose=0)\n",
    "\n",
    "  # Denormalize input for further processing\n",
    "  samples, points, variables = X_exp.shape\n",
    "  X_exp = np.reshape(X_exp, newshape=(-1, variables))\n",
    "  X_exp = scaler.inverse_transform(X_exp)\n",
    "  X_exp = np.reshape(X_exp, newshape=(samples, points, variables))\n",
    "\n",
    "  # Denormalize output predictions\n",
    "  samples, points, variables = Y_exp_pred.shape\n",
    "  Y_exp_pred = np.reshape(Y_exp_pred, newshape=(-1, variables))\n",
    "  Y_exp_pred = scalery.inverse_transform(Y_exp_pred)\n",
    "  Y_exp_pred = np.reshape(Y_exp_pred, newshape=(samples, points, variables))\n",
    "\n",
    "  # Read grid data to get cell areas for weighting\n",
    "  df = pd.read_csv(grid_data, sep=' ')\n",
    "  cell_area = np.array(df.Cell_Volume)\n",
    "  mean_area = np.mean(cell_area)\n",
    "  cell_area = cell_area / mean_area  # Normalize cell areas\n",
    "\n",
    "  # Combine input and predicted output into a DataFrame\n",
    "  df_combined = np.concatenate((X_exp[0, :, :], Y_exp_pred[0, :, :]), axis=1)\n",
    "  df_combined = pd.DataFrame(df_combined, columns=[\n",
    "    'x', 'y', 'z', 'Mach', 'AoA',\n",
    "    'Pressure_Coefficient', 'Skin_Friction_Coefficient_x',\n",
    "    'Skin_Friction_Coefficient_y', 'Skin_Friction_Coefficient_z'\n",
    "  ])\n",
    "\n",
    "  # Extract predicted coefficients\n",
    "  pressure_dataset = df_combined.Pressure_Coefficient\n",
    "  cf_x_dataset = df_combined.Skin_Friction_Coefficient_x\n",
    "  cf_y_dataset = df_combined.Skin_Friction_Coefficient_y\n",
    "  cf_z_dataset = df_combined.Skin_Friction_Coefficient_z\n",
    "\n",
    "  # Prepare dataset dictionary for further calculations\n",
    "  dataset = {\n",
    "    'PointID': cooordinates.PointID,\n",
    "    'x': cooordinates.x,\n",
    "    'y': cooordinates.y,\n",
    "    'z': cooordinates.z,\n",
    "    'Pressure_Coefficient': pressure_dataset,\n",
    "    'Skin_Friction_Coefficient_x': cf_x_dataset,\n",
    "    'Skin_Friction_Coefficient_y': cf_y_dataset,\n",
    "    'Skin_Friction_Coefficient_z': cf_z_dataset\n",
    "  }\n",
    "\n",
    "  # Convert AoA to radians for trigonometric calculations\n",
    "  aoa = AoA * np.pi / 180\n",
    "\n",
    "  # Read grid data again for normal vectors and cell areas\n",
    "  df_cfd = pd.read_csv(grid_data, sep=' ')\n",
    "  nn_data = pd.DataFrame(data=dataset)\n",
    "\n",
    "  def compute_aero_coeff(ds):\n",
    "    \"\"\"\n",
    "    Computes aerodynamic lift, drag, and moment coefficients.\n",
    "\n",
    "    Parameters:\n",
    "      ds (pd.DataFrame): DataFrame containing surface data and predicted coefficients.\n",
    "\n",
    "    Returns:\n",
    "      tuple: (lift, drag, moment)\n",
    "    \"\"\"\n",
    "    coordinates = [ds.x, ds.y, ds.z]  # Surface coordinates\n",
    "    shear = [\n",
    "      ds.Skin_Friction_Coefficient_x,\n",
    "      ds.Skin_Friction_Coefficient_y,\n",
    "      ds.Skin_Friction_Coefficient_z\n",
    "    ]  # Shear coefficients\n",
    "    cp = ds.Pressure_Coefficient  # Pressure coefficient\n",
    "    normal = [\n",
    "      df_cfd.X_Grid_K_Unit_Normal,\n",
    "      df_cfd.Y_Grid_K_Unit_Normal,\n",
    "      df_cfd.Z_Grid_K_Unit_Normal\n",
    "    ]  # Surface normals\n",
    "    cell_area = df_cfd.Cell_Volume  # Cell areas\n",
    "\n",
    "    # Calculate force components per area\n",
    "    taux = (shear[0] - normal[0] * cp) / area\n",
    "    tauz = (shear[2] - normal[2] * cp) / area\n",
    "\n",
    "    # Integrate force components over the surface\n",
    "    fz = np.sum(tauz * cell_area)\n",
    "    fx = np.sum(taux * cell_area)\n",
    "\n",
    "    # Calculate lift and drag using AoA\n",
    "    lift = fz * np.cos(aoa) - fx * np.sin(aoa)\n",
    "    drag = fx * np.cos(aoa) + fz * np.sin(aoa)\n",
    "\n",
    "    # Calculate aerodynamic moment about reference point\n",
    "    my = (\n",
    "      coordinates[2] * (taux * np.cos(aoa) + tauz * np.sin(aoa))\n",
    "      - (coordinates[0] - xref) * (tauz * np.cos(aoa) - taux * np.sin(aoa))\n",
    "    ) / chord\n",
    "    moment = np.sum(my * cell_area)\n",
    "    return lift, drag, moment\n",
    "\n",
    "  # Compute aerodynamic coefficients from predicted data\n",
    "  lift_NN, drag_NN, moment_NN = compute_aero_coeff(nn_data)\n",
    "\n",
    "  return lift_NN, moment_NN  # Return lift and moment predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a92121",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "### PREDICTION FOR STATIC DEFORMATION\n",
    "########################################\n",
    "\n",
    "print(\"\\n\")\n",
    "print('Prediction for static aeroelastic twist angle')\n",
    "print(\"\\n\")\n",
    "\n",
    "Mach = 0.74  # Mach number\n",
    "alpha_range = [0.0, 1.15, 3.15, 4.0, 5.0]  # Angle of attack values (deg)\n",
    "\n",
    "# 2DOF SS system parameters\n",
    "mass = 87.91  # kg\n",
    "Iy = 3.765    # kg m^2\n",
    "kz = mass * (3.33 * 2 * np.pi) ** 2  # Plunge stiffness (N/m)\n",
    "ktheta = Iy * (5.20 * 2 * np.pi) ** 2  # Pitch stiffness (Nm/rad)\n",
    "V = Mach * np.sqrt(1.116 * 81.49 * 304.2128)  # Flight velocity (m/s)\n",
    "\n",
    "theta_values_range = []  # To store theta values for each AoA\n",
    "dynamic_pressure_range = []  # To store dynamic pressure for each AoA\n",
    "\n",
    "# Define the stiffness matrix for the system\n",
    "K_aa = np.array([[ktheta, 0], [0, kz]])\n",
    "\n",
    "for alpha0 in alpha_range:\n",
    "  print('AoA = ' + str(alpha0))  # Print current angle of attack\n",
    "  theta_values = []  # Store theta for this AoA\n",
    "  dynamic_pressure = []  # Store dynamic pressure for this AoA\n",
    "\n",
    "  for rho_value in np.arange(0.0, 1.3, 0.1):  # Loop over density ratios\n",
    "    rho = 1.1751 * rho_value  # Air density (kg/m^3)\n",
    "    q = 0.5 * rho * V * V  # Dynamic pressure (N/m^2)\n",
    "    print('Dynamic pressure = ' + str(int(q / 47.88)))  # Print dynamic pressure in psf\n",
    "    input_vector_old = np.array([0, 0])  # Initial guess for [theta, plunge]\n",
    "    alpha_temp = alpha0  # Temporary AoA for iteration\n",
    "\n",
    "    for i in range(1000):  # Iterative solver for static equilibrium\n",
    "      # Predict CL and CM using the neural network\n",
    "      CL_pred, CM_pred_temp = neural_network(Mach, alpha_temp, npts=X.shape[1], X_temp=X_test[0, :, :3])\n",
    "      CM_pred = CM_pred_temp + (x_50 - x_30) * CL_pred / chord  # Adjust CM for reference point\n",
    "\n",
    "      lift_pred = CL_pred * q * area  # Predicted lift (N)\n",
    "      moment_pred = CM_pred * q * area * chord  # Predicted moment (Nm)\n",
    "\n",
    "      output = np.array([moment_pred, lift_pred])  # Output vector [moment, lift]\n",
    "\n",
    "      inv_K_aa = np.linalg.inv(K_aa)  # Inverse of stiffness matrix\n",
    "      beta = 0.5  # Relaxation factor for convergence\n",
    "      input_vector = np.dot(inv_K_aa, output) * beta + input_vector_old * (1 - beta)  # Update input vector\n",
    "\n",
    "      theta = input_vector[0]  # Extract theta (twist angle)\n",
    "      plunge = input_vector[1]  # Extract plunge (vertical displacement)\n",
    "\n",
    "      alpha_temp = alpha0 + np.rad2deg(theta)  # Update AoA with twist\n",
    "\n",
    "      # Check for convergence in theta\n",
    "      if np.abs(theta - input_vector_old[0]) < 1e-6:\n",
    "        break\n",
    "\n",
    "      input_vector_old = input_vector  # Update for next iteration\n",
    "\n",
    "    theta_values.append(theta)  # Store converged theta\n",
    "    dynamic_pressure.append(q)  # Store corresponding dynamic pressure\n",
    "\n",
    "  theta_values_range.append(theta_values)  # Store all theta for this AoA\n",
    "  dynamic_pressure_range.append(dynamic_pressure)  # Store all q for this AoA\n",
    "\n",
    "# Convert results to numpy arrays and degrees\n",
    "theta_values_range = np.array(np.rad2deg(theta_values_range))  # Convert theta to degrees\n",
    "dynamic_pressure_range = np.array(dynamic_pressure_range)  # Dynamic pressure array\n",
    "\n",
    "# Create column names for CSV\n",
    "columns = ['q'] + [f'theta_{alpha}_deg' for alpha in alpha_range]\n",
    "\n",
    "# Combine dynamic pressure and theta values for CSV\n",
    "data = np.hstack((np.expand_dims(dynamic_pressure_range[0, :], axis=1), theta_values_range.T))\n",
    "\n",
    "# Save results to CSV file\n",
    "filename = 'Static_aeroelastic_twist_angles.csv'\n",
    "with open(filename, 'w', newline='') as file:\n",
    "  writer = csv.writer(file)\n",
    "  writer.writerow(columns)  # Write header\n",
    "  writer.writerows(data)    # Write data rows\n",
    "\n",
    "# Plotting\n",
    "colors = ['cyan', 'pink', 'orange', 'green', 'grey', 'yellow']  # Colors for each AoA\n",
    "circle_size = 80  # Size of scatter points\n",
    "linewidth_ = 3  # Line width for plots\n",
    "plt.rcParams.update({'font.size': 24})  # Set font size for plot\n",
    "fig, ax = plt.subplots(1, 1)  # Create figure and axis\n",
    "fig.set_size_inches(18.5, 10.5)  # Set figure size\n",
    "\n",
    "for i in range(len(alpha_range)):\n",
    "  ax.plot(dynamic_pressure_range[i, :] / 47.88, theta_values_range[i, :], linewidth=linewidth_,\n",
    "      color=colors[i], label='AoA = ' + str(alpha_range[i]))  # Plot theta vs q for each AoA\n",
    "\n",
    "# Plot experimental data as scatter points\n",
    "ax.scatter(exp_0_deg_q, exp_0_deg_theta, color=colors[0], edgecolors='black', s=circle_size)\n",
    "ax.scatter(exp_1_15_deg_q, exp_1_15_deg_theta, color=colors[1], edgecolors='black', s=circle_size)\n",
    "ax.scatter(exp_3_15_deg_q, exp_3_15_deg_theta, color=colors[2], edgecolors='black', s=circle_size)\n",
    "ax.scatter(exp_4_deg_q, exp_4_deg_theta, color=colors[3], edgecolors='black', s=circle_size)\n",
    "ax.scatter(exp_5_deg_q, exp_5_deg_theta, color=colors[4], edgecolors='black', s=circle_size)\n",
    "\n",
    "ax.set_xlabel(r'$Dynamic \\,\\, Pressure \\,\\, [psf]$')  # X-axis label\n",
    "ax.set_ylabel(r'$\\theta \\,\\, [deg]$')  # Y-axis label\n",
    "ax.set_xlim(0, 250)  # Set x-axis limits\n",
    "ax.grid()  # Show grid\n",
    "ax.legend(loc='upper left', fontsize=22)  # Show legend\n",
    "plt.show()  # Display plot\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
