{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c401c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import *\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import chaospy\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c574eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d35a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'Model_architecture\\\\FCNN_v1\\\\'\n",
    "\n",
    "# Inputs for aerodynamic forces estimation\n",
    "xref = 0.12192      # Reference point for moment calculation (e.g., aerodynamic center)\n",
    "chord = 0.4064      # Chord length of the airfoil/wing\n",
    "x_30 = 0.12192      # x-location at 30% chord\n",
    "x_50 = 0.2032       # x-location at 50% chord\n",
    "span = chord*2      # Span of the wing (assuming aspect ratio or geometry)\n",
    "area = span*chord   # Reference area for aerodynamic coefficients\n",
    "\n",
    "\n",
    "# Create directories for the results\n",
    "directory_results = 'Results\\\\Polars_UQ\\\\'\n",
    "Path(directory_results).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "dataset = np.load('Dataset_NN\\\\dataset.npy')\n",
    "grid_data = 'Dataset\\\\grid_data.dat'\n",
    "CFD_csv_file = 'Dataset\\\\surface.csv' # File with normals and cell area\n",
    "\n",
    "# print( '\\n-> Shape of the loaded matrix: \\n')\n",
    "# print(dataset.shape) # x, y , z , CP , CF_x, CF_y, CF_z, M , AoA\n",
    "\n",
    "X = dataset[:,:,[0,1,2,7,8]] # Input\n",
    "Y = dataset[:,:,3:7]         # Output\n",
    "\n",
    "\n",
    "## Feature normalisation:\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "samples, points, variables = X.shape\n",
    "X = np.reshape(X, newshape=(-1, variables))\n",
    "X = scaler.fit_transform(X)\n",
    "X = np.reshape(X, newshape=(samples, points, variables))\n",
    "\n",
    "scalery = MinMaxScaler(feature_range=(-1, 1))\n",
    "samples, points, variables = Y.shape\n",
    "Y = np.reshape(Y, newshape=(-1, variables))\n",
    "Y = scalery.fit_transform(Y)\n",
    "Y = np.reshape(Y, newshape=(samples, points, variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f06cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_dir+ 'neural_network_model.h5')  # Load the model architecture and weights\n",
    "model.load_weights(model_dir+ 'neural_network_weights.h5')  # Load the model weights separately (if needed)\n",
    "print(model.summary())  # Print the model summary\n",
    "\n",
    "# Denormalize\n",
    "samples, points, variables = X.shape  # Get the shape of the normalized input data\n",
    "X_test = np.reshape(X, newshape=(-1, variables))  # Flatten the input data for inverse transformation\n",
    "X_test = scaler.inverse_transform(X_test)  # Inverse transform to original scale\n",
    "X_test = np.reshape(X_test, newshape=(samples, points, variables))  # Reshape back to original dimensions\n",
    "\n",
    "cooordinates = pd.read_csv(CFD_csv_file)  # Load coordinates surface data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e90faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(Mach, AoA, npts, X_temp):\n",
    "  \"\"\"\n",
    "  Predicts aerodynamic coefficients (lift and moment) using a trained neural network model.\n",
    "\n",
    "  Parameters:\n",
    "  Mach (float): Mach number for prediction.\n",
    "  AoA (float): Angle of attack in degrees.\n",
    "  npts (int): Number of points in the input grid.\n",
    "  X_temp (np.ndarray): Array of shape (npts, 3) containing x, y, z coordinates.\n",
    "\n",
    "  Returns:\n",
    "  tuple: Predicted lift and moment coefficients.\n",
    "  \"\"\"\n",
    "  # Create arrays for Mach and AoA, repeated for each point\n",
    "  Mach_i = np.full((npts, 1), Mach)  # Shape (npts, 1)\n",
    "  AoA_i = np.full((npts, 1), AoA)    # Shape (npts, 1)\n",
    "\n",
    "  # Concatenate coordinates with Mach and AoA to form input features\n",
    "  X_exp = np.concatenate((X_temp, Mach_i, AoA_i), axis=1)  # Shape (npts, 5)\n",
    "\n",
    "  # Normalize input features using the fitted scaler\n",
    "  X_exp = scaler.transform(X_exp)\n",
    "  X_exp = np.expand_dims(X_exp, axis=0)  # Add batch dimension\n",
    "\n",
    "  # Predict using the neural network model\n",
    "  Y_exp_pred = model.predict(X_exp, batch_size=1, verbose=0)\n",
    "\n",
    "  # Inverse transform input features to original scale\n",
    "  samples, points, variables = X_exp.shape\n",
    "  X_exp = np.reshape(X_exp, newshape=(-1, variables))\n",
    "  X_exp = scaler.inverse_transform(X_exp)\n",
    "  X_exp = np.reshape(X_exp, newshape=(samples, points, variables))\n",
    "\n",
    "  # Inverse transform predictions to original scale\n",
    "  samples, points, variables = Y_exp_pred.shape\n",
    "  Y_exp_pred = np.reshape(Y_exp_pred, newshape=(-1, variables))\n",
    "  Y_exp_pred = scalery.inverse_transform(Y_exp_pred)\n",
    "  Y_exp_pred = np.reshape(Y_exp_pred, newshape=(samples, points, variables))\n",
    "\n",
    "  # Read grid data to get cell areas for force integration\n",
    "  df = pd.read_csv(grid_data, sep=' ')\n",
    "  cell_area = np.array(df.Cell_Volume)\n",
    "  mean_area = np.mean(cell_area)\n",
    "  cell_area = cell_area / mean_area  # Normalize cell areas\n",
    "\n",
    "  # Prepare DataFrame with predictions and input features\n",
    "  df_pred = np.concatenate((X_exp[0, :, :], Y_exp_pred[0, :, :]), axis=1)\n",
    "  df_pred = pd.DataFrame(df_pred, columns=[\n",
    "    'x', 'y', 'z', 'Mach', 'AoA',\n",
    "    'Pressure_Coefficient', 'Skin_Friction_Coefficient_x',\n",
    "    'Skin_Friction_Coefficient_y', 'Skin_Friction_Coefficient_z'\n",
    "  ])\n",
    "\n",
    "  # Extract predicted aerodynamic coefficients\n",
    "  pressure_dataset = df_pred.Pressure_Coefficient\n",
    "  cf_x_dataset = df_pred.Skin_Friction_Coefficient_x\n",
    "  cf_y_dataset = df_pred.Skin_Friction_Coefficient_y\n",
    "  cf_z_dataset = df_pred.Skin_Friction_Coefficient_z\n",
    "\n",
    "  # Build dataset dictionary for further processing\n",
    "  dataset = {\n",
    "    'PointID': cooordinates.PointID,\n",
    "    'x': cooordinates.x,\n",
    "    'y': cooordinates.y,\n",
    "    'z': cooordinates.z,\n",
    "    'Pressure_Coefficient': pressure_dataset,\n",
    "    'Skin_Friction_Coefficient_x': cf_x_dataset,\n",
    "    'Skin_Friction_Coefficient_y': cf_y_dataset,\n",
    "    'Skin_Friction_Coefficient_z': cf_z_dataset\n",
    "  }\n",
    "\n",
    "  # Convert AoA to radians for trigonometric calculations\n",
    "  aoa = AoA * np.pi / 180\n",
    "\n",
    "  # Read grid data again for normal vectors and cell areas\n",
    "  df_cfd = pd.read_csv(grid_data, sep=' ')\n",
    "  nn_data = pd.DataFrame(data=dataset)\n",
    "\n",
    "  def compute_aero_coeff(ds):\n",
    "    \"\"\"\n",
    "    Computes aerodynamic coefficients (lift, drag, moment) from predicted data.\n",
    "\n",
    "    Parameters:\n",
    "    ds (pd.DataFrame): DataFrame containing coordinates and predicted coefficients.\n",
    "\n",
    "    Returns:\n",
    "    tuple: lift, drag, and moment coefficients.\n",
    "    \"\"\"\n",
    "    coordinates = [ds.x, ds.y, ds.z]  # Coordinates arrays\n",
    "    shear = [ds.Skin_Friction_Coefficient_x, ds.Skin_Friction_Coefficient_y, ds.Skin_Friction_Coefficient_z]  # Shear coefficients\n",
    "    cp = ds.Pressure_Coefficient  # Pressure coefficient\n",
    "    normal = [df_cfd.X_Grid_K_Unit_Normal, df_cfd.Y_Grid_K_Unit_Normal, df_cfd.Z_Grid_K_Unit_Normal]  # Surface normals\n",
    "    cell_area = df_cfd.Cell_Volume  # Cell areas\n",
    "\n",
    "    # Calculate force components per area\n",
    "    taux = (shear[0] - normal[0] * cp) / area\n",
    "    tauz = (shear[2] - normal[2] * cp) / area\n",
    "\n",
    "    # Integrate force components over the surface\n",
    "    fz = np.sum(tauz * cell_area)\n",
    "    fx = np.sum(taux * cell_area)\n",
    "\n",
    "    # Calculate lift and drag using AoA\n",
    "    lift = fz * np.cos(aoa) - fx * np.sin(aoa)\n",
    "    drag = fx * np.cos(aoa) + fz * np.sin(aoa)\n",
    "\n",
    "    # Calculate moment coefficient\n",
    "    my = (coordinates[2] * (taux * np.cos(aoa) + tauz * np.sin(aoa)) -\n",
    "        (coordinates[0] - xref) * (tauz * np.cos(aoa) - taux * np.sin(aoa))) / chord\n",
    "    moment = np.sum(my * cell_area)\n",
    "    return lift, drag, moment\n",
    "\n",
    "  # Compute lift and moment from predictions\n",
    "  lift_NN, drag_NN, moment_NN = compute_aero_coeff(nn_data)\n",
    "\n",
    "  return lift_NN, moment_NN  # Return lift and moment coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e458b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "### PREDICTION FOR POLARS UQ\n",
    "########################################\n",
    "\n",
    "\n",
    "Mach_polars = [0.74 , 0.76 , 0.78 , 0.80 , 0.82 , 0.84]  # List of Mach numbers for the polars\n",
    "AoA_polars = np.arange(0.0,5.1,0.1)  # Range of angle of attack values from 0 to 5 degrees\n",
    "\n",
    "for Mach in Mach_polars:  # Loop over each Mach number\n",
    "  lift_list = []  # Initialize list to store lift coefficients\n",
    "  for AoA in AoA_polars:  # Loop over each angle of attack\n",
    "    lift_temp = neural_network(Mach, AoA)  # Predict lift and moment using the neural network\n",
    "    lift_list.append(lift_temp)  # Append the predicted lift (and moment) to the list\n",
    "\n",
    "  fig, ax = plt.subplots(1, 1, figsize=(18.5, 10.5))\n",
    "  title_plot = 'Lift Polar - M = '+str(Mach)\n",
    "  print('\\n' + title_plot)\n",
    "  fig.suptitle(title_plot, fontsize=16)\n",
    "  ax.plot(AoA_polars,np.array(lift_list),'k-',linewidth=2)  \n",
    "  ax.set_xlabel(r'$AoA \\,\\, [Deg]$', fontsize=16)\n",
    "  ax.set_ylabel(r'$Lift \\,\\, Coefficient$', fontsize=16)\n",
    "  name_fig = 'Lift_polar_Mach_'+str(Mach)\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fc6f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "### PREDICTION FOR POLARS UQ\n",
    "########################################\n",
    "print(\"\\n\")\n",
    "print('PREDICTION FOR POLARS UQ')\n",
    "print(\"\\n\")\n",
    "\n",
    "Mach_list = [0.84, 0.84, 0.84, 0.8, 0.8, 0.8, 0.76, 0.76, 0.76]  # List of Mach numbers for each subplot\n",
    "Mach_range = 0.01  # Standard deviation for Mach number distribution\n",
    "\n",
    "AoA_list = [1.0, 3.0, 5.0, 1.0, 3.0, 5.0, 1.0, 3.0, 5.0]  # List of AoA values for each subplot\n",
    "AoA_range = 0.1  # Standard deviation for AoA distribution\n",
    "\n",
    "random_variables = 2  # Number of random variables (Mach and AoA)\n",
    "poly_order = 5  # Polynomial order for expansion (used for num_samples calculation)\n",
    "num_samples = int(math.factorial(random_variables + poly_order) / (math.factorial(random_variables) * math.factorial(poly_order)))  # Number of samples for regression\n",
    "\n",
    "poly_order = 4  # Polynomial order for the actual expansion\n",
    "\n",
    "plt.rcParams.update({'font.size': 24})  # Set global font size for plots\n",
    "fig = plt.figure(figsize=(18.5, 10.5))  # Create a new figure\n",
    "gs = fig.add_gridspec(5, 5, width_ratios=[0.05, 1, 1, 1, 0.05], height_ratios=[0.05, 1, 1, 1, 0.1], wspace=0.5, hspace=1.0)  # Define grid layout\n",
    "\n",
    "ax_main = fig.add_subplot(gs[:, :])  # Main axis for labels\n",
    "ax_main.set_ylabel(r'$Mach$',labelpad=20)  # Set y-axis label\n",
    "ax_main.set_xlabel(r'$Angle \\, of \\, attack \\,\\, [deg]$',labelpad=20)  # Set x-axis label\n",
    "ax_main.set_ylim([0,10])  # Set y-axis limits\n",
    "ax_main.set_yticks([2,5,8])  # Set y-tick positions\n",
    "ax_main.set_yticklabels(['0.76', '0.80', '0.84'])  # Set y-tick labels\n",
    "ax_main.set_xlim([0,10])  # Set x-axis limits\n",
    "ax_main.set_xticks([2,5,8])  # Set x-tick positions\n",
    "ax_main.set_xticklabels([ '1.0', '3.0', '5.0'])  # Set x-tick labels\n",
    "\n",
    "subplots = []  # List to store individual subplot axes\n",
    "\n",
    "for i, (Mach, AoA) in enumerate(zip(Mach_list, AoA_list)):\n",
    "    row = i // 3  # Calculate row index in grid\n",
    "    col = i % 3   # Calculate column index in grid\n",
    "\n",
    "    title_plot = 'M = {} - AoA = {}'.format(Mach, AoA)  # Title for current subplot\n",
    "    print('\\n' + title_plot)\n",
    "\n",
    "    Mach_dist = chaospy.Normal(Mach, Mach_range)  # Define normal distribution for Mach\n",
    "    AoA_dist = chaospy.Normal(AoA, AoA_range)     # Define normal distribution for AoA\n",
    "    joint = chaospy.J(Mach_dist, AoA_dist)        # Create joint distribution\n",
    "\n",
    "    expansion = chaospy.generate_expansion(poly_order, joint)  # Generate polynomial chaos expansion\n",
    "\n",
    "    samples = joint.sample(num_samples, rule=\"latin_hypercube\", seed=1)  # Sample input space\n",
    "\n",
    "    evaluations = np.array([neural_network(Mach_sample, AoA_sample) for Mach_sample, AoA_sample in samples.T])  # Evaluate NN for each sample\n",
    "\n",
    "    approx_solver = chaospy.fit_regression(expansion, samples, evaluations)  # Fit regression model\n",
    "\n",
    "    num_samples_eval = 10000  # Number of samples for evaluation\n",
    "\n",
    "    samples_eval = joint.sample(num_samples_eval, rule=\"latin_hypercube\", seed=1)  # Generate evaluation samples\n",
    "\n",
    "    approximations = chaospy.call(approx_solver, samples_eval)  # Get approximated outputs\n",
    "    binss = 100  # Number of bins for histogram\n",
    "    bin_edges = np.linspace(approximations.min(), approximations.max(), binss)  # Bin edges for histogram\n",
    "\n",
    "    ax = fig.add_subplot(gs[row + 1, col + 1])  # Create subplot at correct grid position\n",
    "    ax.hist(approximations, bins=bin_edges, density=True, edgecolor='black', color='grey',\n",
    "            alpha=0.7)  # Plot histogram of approximations\n",
    "    # ax.legend(loc='upper left', fontsize=10)\n",
    "    ax.set_xlabel(r'$C_L$')  # Set x-axis label\n",
    "    ax.set_ylabel(r'$PDF$')  # Set y-axis label\n",
    "\n",
    "    subplots.append(ax)  # Add the subplot axes to the list\n",
    "\n",
    "# Call the desired subplot outside the for loop\n",
    "subplots[0].set_xlim([-0.1, 0.4])      # Set x-axis limits for subplot 0\n",
    "subplots[1].set_xlim([-0.07, 0.52])    # Set x-axis limits for subplot 1\n",
    "subplots[3].set_xlim([0.24, 0.355])    # Set x-axis limits for subplot 3\n",
    "subplots[4].set_xlim([0.38, 0.56])     # Set x-axis limits for subplot 4\n",
    "subplots[5].set_xlim([0.3, 0.9])       # Set x-axis limits for subplot 5\n",
    "\n",
    "plt.show()  # Display the figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d984a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "### PREDICTION FOR POLARS UQ\n",
    "########################################\n",
    "print(\"\\n\")\n",
    "print('PREDICTION FOR POLARS UQ')\n",
    "print(\"\\n\")\n",
    "\n",
    "Mach_list = [0.74, 0.76, 0.80, 0.82, 0.84 ]  # List of Mach numbers to analyze\n",
    "Mach_range = 0.01  # Standard deviation for Mach number uncertainty\n",
    "\n",
    "AoA_list = [1.0, 3.0, 5.0 ]  # List of angles of attack to analyze\n",
    "AoA_range = 0.1  # Standard deviation for AoA uncertainty\n",
    "\n",
    "random_variables = 2  # Number of uncertain input variables (Mach, AoA)\n",
    "poly_order = 5  # Maximum polynomial order for expansion (for num_samples calculation)\n",
    "num_samples = int(math.factorial(random_variables + poly_order) / (math.factorial(random_variables) * math.factorial(poly_order)))  # Number of samples for regression\n",
    "\n",
    "poly_ord_min = 1  # Minimum polynomial order for subplots\n",
    "poly_ord_max = 5  # Maximum polynomial order for subplots\n",
    "\n",
    "for Mach in Mach_list:  # Loop over Mach numbers\n",
    "    for AoA in AoA_list:  # Loop over AoA values\n",
    "        # Create a figure with subplots for each polynomial order\n",
    "        plt.rcParams.update({'font.size': 24})  # Set font size for plots\n",
    "        fig, axs = plt.subplots((poly_ord_max+1 - poly_ord_min), 1, figsize=(18.5, 10.5))  # Create subplots for each poly order\n",
    "        title_plot = 'UQ Polars - M = '+str(Mach)+' - AoA = '+str(AoA)\n",
    "        print('\\n' + title_plot)\n",
    "        fig.suptitle(title_plot, fontsize=16)  # Set figure title\n",
    "\n",
    "        Mach_dist = chaospy.Normal(Mach, Mach_range)  # Define normal distribution for Mach\n",
    "        AoA_dist = chaospy.Normal(AoA, AoA_range)  # Define normal distribution for AoA\n",
    "        joint = chaospy.J(Mach_dist, AoA_dist)  # Create joint distribution\n",
    "\n",
    "        expansion = chaospy.generate_expansion(poly_ord_max, joint)  # Generate polynomial chaos expansion\n",
    "\n",
    "        samples = joint.sample(num_samples, rule=\"latin_hypercube\", seed=1)  # Sample input space\n",
    "\n",
    "        evaluations = np.array([neural_network(Mach_sample, AoA_sample) for Mach_sample, AoA_sample in samples.T])  # Evaluate NN for each sample\n",
    "\n",
    "        approx_solver = chaospy.fit_regression(expansion, samples, evaluations)  # Fit regression model\n",
    "\n",
    "        num_samples_eval = 10000  # Number of samples for evaluation\n",
    "\n",
    "        samples_eval = joint.sample(num_samples_eval, rule=\"latin_hypercube\", seed=1)  # Generate evaluation samples\n",
    "\n",
    "        approximations = chaospy.call(approx_solver, samples_eval)  # Get approximated outputs\n",
    "        binss = 500  # Number of bins for histogram\n",
    "        bin_edges = np.linspace(approximations.min(), approximations.max(), binss)  # Bin edges for histogram\n",
    "\n",
    "        # Iterate over each poly_order value\n",
    "        for i, poly_order in enumerate(range(poly_ord_min, poly_ord_max+1)):\n",
    "                Mach_dist = chaospy.Normal(Mach, Mach_range)  # Redefine Mach distribution for current poly order\n",
    "                AoA_dist = chaospy.Normal(AoA, AoA_range)  # Redefine AoA distribution for current poly order\n",
    "                joint = chaospy.J(Mach_dist, AoA_dist)  # Create joint distribution\n",
    "\n",
    "                expansion = chaospy.generate_expansion(poly_order, joint)  # Generate polynomial chaos expansion\n",
    "\n",
    "                samples = joint.sample(num_samples, rule=\"latin_hypercube\", seed=1)  # Sample input space\n",
    "\n",
    "                evaluations = np.array([neural_network(Mach_sample, AoA_sample) for Mach_sample, AoA_sample in samples.T])  # Evaluate NN for each sample\n",
    "\n",
    "                approx_solver = chaospy.fit_regression(expansion, samples, evaluations)  # Fit regression model\n",
    "\n",
    "                num_samples_eval = 10000  # Number of samples for evaluation\n",
    "\n",
    "                samples_eval = joint.sample(num_samples_eval, rule=\"latin_hypercube\", seed=1)  # Generate evaluation samples\n",
    "\n",
    "                approximations = chaospy.call(approx_solver, samples_eval)  # Get approximated outputs\n",
    "\n",
    "                axs[i].hist(approximations, bins=bin_edges, density=True, edgecolor='black', color='grey', alpha=0.7, label=f'Poly Order: {poly_order}')  # Plot histogram\n",
    "                axs[i].legend(loc='upper left')  # Show legend\n",
    "                axs[i].set_ylabel(r'$PDF$')  # Set y-axis label\n",
    "\n",
    "        axs[i].set_xlabel(r'$C_L$')  # Set x-axis label for the last subplot\n",
    "        \n",
    "        approx_min = 0.4 #np.min(approximations)  # Set minimum x-axis value (can be adjusted)\n",
    "        approx_max = 0.6 #np.max(approximations)  # Set maximum x-axis value (can be adjusted)\n",
    "\n",
    "        # Set a global min and max value for the x-axis across all subplots\n",
    "        for j, ax in enumerate(axs):\n",
    "                if j < len(axs) - 1:\n",
    "                        ax.set_xticks([])  # Hide x-ticks for all but last subplot\n",
    "                ax.set_xlim(approx_min, approx_max)  # Set x-axis limits\n",
    "\n",
    "        plt.tight_layout()  # Adjust subplot layout\n",
    "        plt.show()  # Display the figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb1c4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "### SOBOL INDICES\n",
    "########################################\n",
    "\n",
    "print(\"\\n\")\n",
    "print('SOBOL INDICES')\n",
    "print(\"\\n\")\n",
    "\n",
    "poly_order = 4  # Set polynomial order for chaos expansion\n",
    "\n",
    "for Mach in Mach_list:  # Loop over Mach numbers\n",
    "    fig1, axs1 = plt.subplots(1, 1, figsize=(9.25, 5.25))  # Create a new figure for each Mach\n",
    "    title_plot_sobol = 'Sobol indices - M = '+str(Mach)\n",
    "    fig1.suptitle(title_plot_sobol, fontsize=16)  # Set figure title\n",
    "\n",
    "    sobol_indices_mach = []  # List to store Sobol indices for Mach\n",
    "    sobol_indices_aoa = []   # List to store Sobol indices for AoA\n",
    "\n",
    "    for AoA in AoA_list:  # Loop over AoA values\n",
    "        Mach_dist = chaospy.Normal(Mach, Mach_range)  # Define normal distribution for Mach\n",
    "        AoA_dist = chaospy.Normal(AoA, AoA_range)     # Define normal distribution for AoA\n",
    "        joint = chaospy.J(Mach_dist, AoA_dist)        # Create joint distribution\n",
    "\n",
    "        expansion = chaospy.generate_expansion(poly_order, joint)  # Generate polynomial chaos expansion\n",
    "\n",
    "        samples = joint.sample(num_samples, rule=\"latin_hypercube\", seed=1)  # Sample input space\n",
    "\n",
    "        evaluations = np.array([neural_network(Mach_sample, AoA_sample) for Mach_sample, AoA_sample in samples.T])  # Evaluate NN for each sample\n",
    "\n",
    "        approx_solver = chaospy.fit_regression(expansion, samples, evaluations)  # Fit regression model\n",
    "\n",
    "        num_samples_eval = 10000  # Number of samples for evaluation\n",
    "\n",
    "        samples_eval = joint.sample(num_samples_eval, rule=\"latin_hypercube\", seed=1)  # Generate evaluation samples\n",
    "\n",
    "        approximations = chaospy.call(approx_solver, samples_eval)  # Get approximated outputs\n",
    "\n",
    "        # Calculate Sobol indices\n",
    "        sobol_indices = chaospy.Sens_m(approx_solver, joint, samples=samples_eval)  # Compute Sobol indices\n",
    "\n",
    "        sobol_indices_mach.append(sobol_indices[0])  # Store Mach Sobol index\n",
    "        sobol_indices_aoa.append(sobol_indices[1])   # Store AoA Sobol index\n",
    "\n",
    "    labels = [str(AoA) for AoA in AoA_list]  # Create labels for AoA values\n",
    "\n",
    "    axs1.bar(labels, sobol_indices_mach, width=0.6, alpha=0.5, label=r'$Mach$')  # Plot Mach Sobol indices\n",
    "    axs1.bar(labels, sobol_indices_aoa, width=0.6, alpha=0.5, label=r'$Angle \\, of \\, attack$', bottom=sobol_indices_mach)  # Plot AoA Sobol indices stacked\n",
    "    axs1.set_xlabel(r'$AoA \\,\\, [Deg]$', fontsize=16)  # Set x-axis label\n",
    "    # axs1.set_ylabel(r'$Sobol \\,\\, Index$', fontsize=16)\n",
    "    axs1.legend(loc='upper right', fontsize=16)  # Show legend\n",
    "    axs1.set_ylim(0.0, 1.1)  # Set y-axis limits\n",
    "    plt.tight_layout()  # Adjust layout\n",
    "    plt.show()  # Display the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9855b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "print('SOBOL INDICES')\n",
    "print(\"\\n\")\n",
    "Mach_list = [0.84, 0.8, 0.76]  # List of Mach numbers to analyze\n",
    "AoA_list = [1, 3, 5]           # List of angles of attack to analyze\n",
    "poly_order = 3                 # Polynomial order for chaos expansion\n",
    "plt.rcParams.update({'font.size': 24})  # Set global font size for plots\n",
    "fig = plt.figure(figsize=(18.5, 10.5))  # Create a new figure\n",
    "gs = fig.add_gridspec(5, 5, width_ratios=[0.05, 0.8, 0.8, 0.8, 0.05], height_ratios=[0.05, 2.0, 2.0, 2.0, 0.1], wspace=0.5, hspace=0.8)  # Define grid layout\n",
    "\n",
    "ax_main = fig.add_subplot(gs[:, :])  # Main axis for labels\n",
    "ax_main.set_ylabel(r'$Mach$', labelpad=20)  # Set y-axis label\n",
    "ax_main.set_xlabel(r'$Angle \\, of \\, attack \\,\\, [deg]$', labelpad=20)  # Set x-axis label\n",
    "ax_main.set_ylim([0, 10])  # Set y-axis limits\n",
    "ax_main.set_yticks([2, 5, 8])  # Set y-tick positions\n",
    "ax_main.set_yticklabels(['0.76', '0.80', '0.84'])  # Set y-tick labels\n",
    "ax_main.set_xlim([0, 10])  # Set x-axis limits\n",
    "ax_main.set_xticks([2, 5, 8])  # Set x-tick positions\n",
    "ax_main.set_xticklabels(['1.0', '3.0', '5.0'])  # Set x-tick labels\n",
    "\n",
    "legend_labels = []  # List to store legend handles\n",
    "\n",
    "for i, Mach in enumerate(Mach_list):  # Loop over Mach numbers\n",
    "    for j, AoA in enumerate(AoA_list):  # Loop over AoA values\n",
    "        sub_ax = fig.add_subplot(gs[i+1, j+1])  # Create subplot for each Mach/AoA combination\n",
    "\n",
    "        sobol_indices_mach = []  # List to store Mach Sobol index\n",
    "        sobol_indices_aoa = []   # List to store AoA Sobol index\n",
    "\n",
    "        Mach_dist = chaospy.Normal(Mach, Mach_range)  # Define normal distribution for Mach\n",
    "        AoA_dist = chaospy.Normal(AoA, AoA_range)     # Define normal distribution for AoA\n",
    "        joint = chaospy.J(Mach_dist, AoA_dist)        # Create joint distribution\n",
    "\n",
    "        expansion = chaospy.generate_expansion(poly_order, joint)  # Generate polynomial chaos expansion\n",
    "\n",
    "        samples = joint.sample(num_samples, rule=\"latin_hypercube\", seed=1)  # Sample input space\n",
    "\n",
    "        evaluations = np.array([neural_network(Mach_sample, AoA_sample) for Mach_sample, AoA_sample in samples.T])  # Evaluate NN for each sample\n",
    "\n",
    "        approx_solver = chaospy.fit_regression(expansion, samples, evaluations)  # Fit regression model\n",
    "\n",
    "        num_samples_eval = 10000  # Number of samples for evaluation\n",
    "\n",
    "        samples_eval = joint.sample(num_samples_eval, rule=\"latin_hypercube\", seed=1)  # Generate evaluation samples\n",
    "\n",
    "        approximations = chaospy.call(approx_solver, samples_eval)  # Get approximated outputs\n",
    "\n",
    "        # Calculate Sobol indices\n",
    "        sobol_indices = chaospy.Sens_m(approx_solver, joint, samples=samples_eval)  # Compute Sobol indices\n",
    "        sobol_indices_mach.append(sobol_indices[0])  # Store Mach Sobol index\n",
    "        sobol_indices_aoa.append(sobol_indices[1])   # Store AoA Sobol index\n",
    "\n",
    "        mach_bar = sub_ax.bar([AoA], sobol_indices_mach, color='grey', width=0.6, alpha=0.5, label=r'$Mach$')  # Plot Mach Sobol index\n",
    "        aoa_bar = sub_ax.bar([AoA], sobol_indices_aoa, color='black', width=0.6, alpha=0.5, label=r'$Angle \\, of \\, attack$', bottom=sobol_indices_mach)  # Plot AoA Sobol index stacked\n",
    "        # sub_ax.set_xlabel(r'$AoA \\,\\, [Deg]$', fontsize=12)\n",
    "        sub_ax.set_ylabel(r'$Sobol \\,\\, Idx$', fontsize=22)  # Set y-axis label\n",
    "        sub_ax.set_ylim(0.0, 1.1)  # Set y-axis limits\n",
    "        sub_ax.set_xticks([])  # Hide x-ticks\n",
    "\n",
    "        # Add label to legend only once\n",
    "        if (i == 0) and (j == 2):  # Only add legend handles once\n",
    "            legend_labels.append(mach_bar[0])\n",
    "            legend_labels.append(aoa_bar[0])\n",
    "\n",
    "ax_main.legend(legend_labels, ['Mach', 'Angle of attack'], loc='upper right', ncol=2 ,fontsize=22)  # Add legend to main axis\n",
    "plt.show()  # Display the figure\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
